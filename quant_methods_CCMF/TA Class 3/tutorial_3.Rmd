---
title: "tutorial_3"
author: "Lir Hoxhaj"
date: "2025-02-07"
output:
  pdf_document: default
  html_document: default
---

# Background

**GOALS OF TUTORIAL**: 

1. Understand RDDs (regression discontinuity design) and why we use them
2. Know how to conduct an RDD analysis in R

**Sources**:

- `firmtax.dta` (source could not be found)
- `mlda.dta` from R Companision to "Real Econometrics" (Carilli, 2021): https://bookdown.org/carillitony/bailey/
- `card_krueger_94.csv` Retrieved from https://davidcard.berkeley.edu/data_sets.html. Card, D., & Krueger, A. B. (2000). Minimum wages and employment: a case study of the fast-food industry in New Jersey and Pennsylvania: reply. *American Economic Review, 90*(5), 1397-1420.

Literature:
- Econometrics with R (Hanck et al., 2024): https://www.econometrics-with-r.org/index.html
- R Companision to "Real Econometrics" (Carilli, 2021): https://bookdown.org/carillitony/bailey/

# Setup

Let's set up a new environment and load our libraries in one place. 

```{r}
rm( list = ls(all.names = TRUE) )

## Installing libraries

if(!require(ggplot2)) install.packages("ggplot2")
if(!require(lmtest)) install.packages("lmtest")
if(!require(AER)) install.packages("AER")
if(!require(dplyr)) install.packages("dplyr") 
if(!require(rdd)) install.packages("rdd") 
if(!require(rddtools)) install.packages("rddtools") 
if(!require(rdrobust)) install.packages("rdrobust") 
if(!require(texreg)) install.packages("texreg") 
if(!require(texreg)) install.packages("texreg") 

## Loading libraries
library(ggplot2)
library(lmtest)
library(AER)
library(dplyr)
library(rdd)
library(rddtools)
library(rdrobust)
library(texreg)
library(plm)


```

Setting up our working directory

```{r}
# Automatically (based on location of this script)
working_directory <- dirname(rstudioapi::getActiveDocumentContext()$path)

# , or manually...
# setwd("C:\\Users\\lhoxhaj\\OneDrive - Imperial College London\\Desktop\\TA\\Shuang\\Tutorials\\Lir\\tutorial_1") # set wd

```



# RDD and DiD

## Motivation

Last time, we talked about IV regression as a method to account for endogeneity (i.e., the error term should not be correlated with any of the independent variables $E[u|X] \neq 0$), a common issue with empirical data. Endogeneity may be because of a **selection problem**, **simultaneous causality**, **omitted variables**, **measurement (observational) error**. 

We said that these issues may be resolved under random assignments, which is why we use RCTs. However, doing experiments with people is unethical and very costly, sometimes even not feasible. This is why many researchers rely on **quasi-experiments**, which allow them to assign the treatment condition, and therefore the control and treatment groups, by using criteria other than random assignment. While this is not the optimal approach, quasi-experiments can still be considered empirically valid and in some cases more feasible and ethically/legally viable to implement than experiments with random assignment.

Two approaches that belong to this category involve:

-   Regression Discontinuity Design (RDD)
-   Difference-in-Difference Estimation (DiD)

# 1. RDD (Regression Discontinuity Design)

## Motivation

As indicated in the lecture, human behaviour is often governed by exogenous rules and constructions imposed by governments. These often take the form of laws and regulations, governing many areas of life including:

-   Smoking/drinking/driving age limits
-   Pension age
-   School cohorts
-   Credit scores
-   Effects of climate change relative to position on the globe
-   Effects of agricultural subsidies

The general idea being that treatment for individuals aged/earning below a limit or threshold is different to those above it (perhaps only true in an ideal world!). Regardless, we will assume a world where the rules are mostly adhered to. These reforms/policies/cutoffs create that **quasi-experimental** setting that *randomly* divides people into two categories, treatment and control groups, which we can then exploit to our advantage to understand the relationship between $Y$ and $X$.

Where these rules are applied, we have what is known as a **discontinuous function** - where the treatment of an observed variable changes as a threshold is passed.

Consider the model:

$$
\Large
Y_i = \beta_0 + \beta_1 D_a + \beta_2 a + u_i
$$

where we are trying to determine the effects of a treatment variable (treatment status) $D_a$ based on the values of a running (continous) variable $a$, so let:

$$
\Large
D_i = 
\begin{cases}
1, \: a_i \ge c \\
0, \: a_i < c
\end{cases}
$$

where $c$ represents the threshold of our continuous variable $a_i$ (e.g. drinking age 21 and age of young people).

*Goal of RDD*: use observations of $a_i$ with values close to $c$ to estimate $\beta_1$, being the average treatment effect for individuals with $a_i = c$.

*Main assumption of RDD*: continuity, meaning in absence of rule/reform/treatment, outcomes $y$ would not have "jumped" (i.e., would have remained smooth). To know this for sure, we could use, if possible, placebo tests to see if there is a "jump" for a different threshold (e.g., move legal drinking age from 18 to 21) and check if there is "bunching"

*Two types of RDD*:

- a **sharp** RDD has treatment assignments that are **deterministic and discontinuous at the threshold**: observations below the cut-off $a_i < c$ do not receive treatment, observations $a_i \ge c$ are treated.
- a **fuzzy** RDD instead considers $c$ to be a **probability of receiving treatment** rather than a certainty, due to potential unobserved factors in determining the precise treatment cut-off. We are not going to cover fuzzy RDD any further in this course.

## Example 1: MVA deaths data

Let's see if drinking and driving is preferable (most likely not, but we can show this through data). We will use a natural experiment, something random, which is being less or 21 and above in the US, and see if there is a significant impact of age which determines the legal age of alcohol, on motor vehicle accident (mva) deaths.

```{r}
# .rda file should be in same folder as .rmd file
load(file = paste0(working_directory, "/mlda.rda"))
```

Selecting only the two important variables we need, deaths and age

```{r}
mlda <- mlda %>%
  select(agecell, mva) %>%
  filter(!is.na(mva) & !is.na(agecell))
```


```{r}
ggplot(mlda, aes(x = agecell, y = mva)) + 
  geom_point() +
  geom_vline(xintercept = 21, color = 'red') + # cutoff (legal drinking age in the US)
  labs(y = "Deaths in Moving Vehicle Accidents", x = "Age") +
  theme_minimal()
```

We are going to create a new dummy variable $treatment$ to indicate "treatment" (whether 21 and above or not) 

```{r}
mlda <- mlda %>%
  mutate(treatment = ifelse(agecell >= 21, 1, 0))  # Binary treatment variable
```


### Regressions

#### Same slope

There appears to be a discontinuity at age 21. Let’s estimate a **linear RDD model (without interaction term)**, with $treatment$ (sometimes $D$ in these outputs) and running variable $agecell$ (distance from age 21)

$$
\Large
mva = \beta_0 + \beta_1treatment + \beta_2(agecell-21)+ u \text{, where:}
\\\Large
treatment_i = 
\begin{cases}
1, \: agecell \ge 21 \\
0, \: agecell < 21
\end{cases}
$$


```{r}
ols_model <- lm(mva ~ agecell, data = mlda)
rdd_model <- lm(mva ~ treatment + I(agecell - 21), data = mlda)
summary(ols_model)
summary(rdd_model)
```

Results:

- $\beta_0 = 29.36$ represents expected MVA deaths per 100,000 population just before the age of 21. 
- After turning 21 (i.e., legally allowed to drink), MVA deaths increase by 4.53 per 100,000 ($\beta_1 = 4.53$), on average. We can say that this jump between regression functions at the threshold can be regarded as **the causal effect of the treatment** (i.e., alcohol on MVA deaths).
- $\beta_3 = -3.1488$ means that MVA deaths tend to decrease with age. $\beta_1$ is showing us that there is a jump in MVA deaths at age 21, suggesting a causal effect of legal drinking on increased fatalities.


```{r}
ggplot(mlda, aes(x = agecell, y = mva)) + 
  geom_point(aes(color = treatment)) +
  geom_smooth(method = "lm", color = "purple", se = FALSE) +  # Add regression line
  geom_vline(xintercept = 21, color = 'red') + # cutoff (legal drinking age in the US)
  labs(y = "Deaths in Moving Vehicle Accidents", x = "Age") +
  theme_minimal()
```


#### Different slope

Let’s now estimate a different **RDD model (with an interaction term)** or *varying slopes*

$$
\Large
mva = \beta_0 + \beta_1treatment + \beta_2(agecell-21)+ \beta_2(agecell-21)*Treatment + u \text{, where:}
\\\Large
treatment_i = 
\begin{cases} 
1, \: agecell \ge 21 \\
0, \: agecell < 21
\end{cases}
$$

```{r}
rdd_model_2 <- lm(mva ~ treatment * I(agecell - 21), data = mlda)
summary(rdd_model_2)
```

$\beta_1$ shows jump is still large and significant. After 21, the decrease in MVA deaths is slightly steeper, but the interaction effect is not statistically significant. This means that the slope before and after do not differ significantly from each other, indicating no change in slope before and after 21. However, it still suggests that the trend of decreasing deaths continues post-21.


Let's plot this now...

```{r}
ggplot(mlda, aes(x = agecell, y = mva, color = factor(treatment))) +
  geom_point() +
  geom_vline(xintercept = 21, color = 'red') + # cutoff (legal drinking age in the US)
  geom_smooth(method = "lm", se = FALSE) +
  scale_color_manual(values = c("darkgreen", "blue")) +
  labs(
    title = "Regression Discontinuity: MLDA Effect on MVA",
    x = "Age",
    y = "Deaths in Moving Vehicle Accidents",
    color = "D"
  ) +
  theme_minimal()

```

You can also plot the same thing using rddtols library's functions

```{r}
rdplot(y = mlda$mva, x = mlda$agecell, 
       c = 21, p = 1, nbins = 100, 
       x.label = "Age", 
       y.label = "Deaths in Moving Vehicle Accidents",
       title = "Regression Discontinuity Plot")
```



Like with `ivreg()`, we can use the *rdd_reg_lm()* function from `rddtols`. We can estimate a model without an intercept term and one with interaction term (varying slope) 

```{r}
rdd_data(mlda$mva, mlda$agecell, cutpoint = 21) %>% 
  rdd_reg_lm(slope = "same") %>% 
  summary()
rdd_data(mlda$mva, mlda$agecell, cutpoint = 21) %>% 
  rdd_reg_lm(slope = "separate") %>% 
  summary()
```


We are assuming this experiment is a **sharp RDD**. In reality (source: many high school movies), will tell you that young adults are very likely to break the law and consume alcohol before they are 21, which may have caused some of these MVA deaths. This would lead us to believe that we are in fact dealing with a **fuzzy RDD** (treatment, alcohol could have been consumed before 21). This is could be a *measurement error* or *selection bias*, which may lead to endogeneity and biased results! We could deal with this using an IV, a factor that could be related to alcohol consumption but not MVA deaths.


## Example 2: Taxes dataset

Let's take a look at another dataset and see if revenue affects profits of firms. 

```{r}
rm( list = ls(all.names = TRUE) )
working_directory <- dirname(rstudioapi::getActiveDocumentContext()$path)

taxes <- read_stata(paste0(working_directory, "/firmtax.dta"))
taxes <- as.data.frame(taxes)
```

We can clearly see a discontinuity in data here, and a decrease in net profit margin on average.

```{r}
rdplot(taxes$prma, taxes$opre, c = 6420000, p=1, nbins=100, x.label = "Operating revenue", 
       y.label = "Net profit margin")
```


### Bunching

**Bunching**, where data is concentrated a bit below or above the cutoff of a running variable, which is more common than one may think, especially in the case of taxes (e.g., people/businesses having a tendency to declare less income than a threshold (amount) to tax authorities).

Visually, we don't see bunching here (not many businesses reporting operating revenue less than 6,420,000).

```{r}
ggplot(taxes, aes(x = opre)) + 
  geom_histogram(fill = "lightblue", color = "black", bins = 150) +
  geom_vline(xintercept = 6420000, color = 'darkmagenta') + # cutoff 
  labs(title = "Histogram: Distribution of Operating revenue of firms (in USD)", x = "Operating revenue (in $)", y = "Frequency") +
  theme_minimal()
```

A "Formal McCrary (2008) test for bunching" refers to a statistical test used to assess whether individuals are manipulating the "running variable" (the variable that determines treatment assignment) around the cutoff point, leading to a discontinuity in the density of that variable / bunching. 

The null hypothesis of this test is that the density of the running variable is continuous at the cutoff point, meaning there is no bunching occurring. The test uses a non-parametric density estimator to compare the density of the running variable just below the cutoff to the density just above the cutoff. If the test rejects the null hypothesis, it indicates a significant discontinuity in the density of the running variable at the cutoff, suggesting potential manipulation and raising concerns about the validity of the RD design. 


```{r}
McCrary_model <- DCdensity(taxes$opre, c = 6420000)
```

### Regressions

We will run an RDD with only an interval (subset) of data and few with entire samples. The reason we do this is because the difference in what the OLS fits predict at the cutoffs could be different using different cutoffs. Using all data for example could likely lead to biased results since it includes firms that are too far from the cutoff.

```{r}
# Linear Model with fixed intervals around the cutoff
taxes <- within(taxes, 
                cutoff <- ifelse(opre >= 6420000, 1, 0))

data1 <- subset(taxes, abs(opre-6420000) < 709000)
data2 <- subset(taxes, abs(opre-6420000) < 500000)
data3 <- taxes %>% 
  filter(!firm_id %in% unique(c(data1$firm_id, data2$firm_id)))

# Create labels and combine data
data1$group <- "Data1 (|opre - 6420000| < 709000)"
data2$group <- "Data2 (|opre - 6420000| < 500000)"
data3$group <- "Data3 (other)"
combined_data <- bind_rows(data1, data2, data3)

# Plot histograms with different colors
ggplot(combined_data, aes(x = opre, fill = group)) +
  geom_histogram(position = "identity", alpha = 0.5, color = "black", bins = 100) +
  geom_vline(xintercept = 6420000, color = 'darkmagenta', linewidth = 1) + # Cutoff line
  labs(title = "Histogram: Distribution of Operating Revenue of Firms", 
       x = "Operating revenue (in $)", 
       y = "Frequency", 
       fill = "Data Subset") +
  scale_fill_manual(values = c("red", "green", "lightblue")) +  # Assign colors manually
  theme_minimal()

```

Instead of summarising both OLS, screenreg from the `texreg` library is a nice way to visualise results.

```{r}
rdd1 <- lm(prma ~ cutoff, data = data1)
# summary(rdd1)

rdd2 <- lm(prma ~ cutoff, data = data2)
# summary(rdd2)

rdd3 <- lm(prma ~ cutoff, data = taxes)
# summary(rdd1)

screenreg(
  list(rdd1, rdd2, rdd3),
  custom.model.names = c(
    "Model 1: (|opre - 6420000| < 500000)",
    "Model 2: (|opre - 6420000| < 709000)",
    "Model 3: All Data"),
  digits = 3,
  omit.coef = "Intercept"
)
```

Let's see other methods that use different intervals:

- *Parametric*: more flexible than standard lm() because it allows separate slopes on each side of the cutoff, but assumes parametric functional form (i.e., linear or polynomial)., like OLS)
- *Nonparametric*: Does not assume a specific functional form (no linearity or polynomial constraints). Instead, uses local regression (Kernel weighting) to estimate treatment effect and gives more weight to observations closer to the cutoff (instead of fitting a global trend), so it best of both worlds in terms of fitting and predicting in our case.

```{r}
# Convert data in data.frame format to rdd project (needed for this library)
rdd_data <- rdd_data(y=taxes$prma, x=taxes$opre, cutpoint=6420000)

# Parametric 
rdd_para <- rdd_reg_lm(rdd_object=rdd_data)
rdd_para 

# Nonparametric
rdd_nonpara <- rdd_reg_np(rdd_object=rdd_data)
rdd_nonpara

```

We see that the non-parametric ML method actually is closer to the estimations we had with smaller intervals than when we used entire data.


# 2. DiD (Difference-in-Difference Estimation)

## Motivation

As covered in the corresponding lecture, IV and RDD regression rely on the assumption that treatment and control groups are **identical** before the treatment (intervention) is applied. However, in reality, we are often confronted with treatment and control groups that are not identical prior to treatment.

DID studies are often conducted to assess the impact of policy changes on a population. As expected, individuals within a population are all different in numerous measures, meaning that we require a tool that can account for these pre-treatment differences and still provide inference as to how a policy change has affected a population. 

Additionally, DID provides a **counterfactual** account of how a population would fare without the treatment (although this is unobserved). DID uses the outcome of the control group to proxy what may have occurred in the treatment group had the intervention not taken place. **Treatment effects** are measured as the difference in average post-treatment outcomes between the two groups.

DID models require an exogenous source of variation - often in the form of a policy change - such as:

-   Changes to minimum wage
-   Implementation of new taxes / subsidies
-   Healthcare or workplace policy design

### Regression equation

The obvious pitfall here is that there may be factors other than the treatment that may induce change over time between the two groups. DID isolates other time-varying factors by subtracting before-after differences for each group from each other, leaving only the estimate of the treatment effect. Formally:

$$
\Large
\begin{aligned}
\hat{\beta_1}^{DID} &= \left(\bar{Y}_{treatment,after} - \bar{Y}_{treatment,before} \right) - \left(\bar{Y}_{control,after} - \bar{Y}_{control,before} \right) \\
&=\Delta\bar{Y}_{treatment} - \Delta\bar{Y}_{control}
\end{aligned}
$$

where:

-   $\bar{Y}_{treatment,before}$ = sample average of **treatment** group **before** treatment
-   $\bar{Y}_{treatment,after}$ = sample average of **treatment** group **after** treatment
-   $\bar{Y}_{control,before}$ = sample average of **control** group **before** treatment
-   $\bar{Y}_{control,after}$ = sample average of **control** group **after** treatment

We refer to the before-after difference in the treatment group ($\bar{Y}_{treatment,before} - \bar{Y}_{treatment,after}$) as the **first difference** ($\Delta\bar{Y}_{treatment}$), and the before-after difference in the control group ($\bar{Y}_{control,before} - \bar{Y}_{control,after}$) as the **second difference** ($\Delta\bar{Y}_{control}$).

In graph form:

```{r, echo=FALSE, out.width = '100%'}
rm( list = ls(all.names = TRUE) )
working_directory <- dirname(rstudioapi::getActiveDocumentContext()$path)

knitr::include_graphics(paste0(working_directory, "/did1.png"), error = FALSE)
```


The simple model for a DID estimator written in OLS notation:

$$
\Large
\Delta Y_i = \beta_0 + \beta_1 X_i + u_i  
$$

where:

-   $\Delta Y_i$ denotes the difference in pre-treatment and post-treatment outcomes for individual $i$
-   $X_i$ denotes the treatment indicator.

Additional explanatory (right-hand side) variables measuring **pre-treatment** characteristics can be added:

$$
\Large
\Delta Y_i = \beta_0 + \beta_1 X_i + \beta_2 W_{1i} + \cdot \cdot \cdot + \beta_{1+r} W_{ri} + u_i
$$

which enables a more precise estimate to be made for $\beta_1$.

#### Parallel Trends Assumption

DID requires multiple assumptions to estimate causal effects, however the most critical assumption is that of **parallel trends**, which dictates that the *difference between treatment and control groups must be constant over time, even in the absence of any treatment effect*. Should the parallel trends assumption be violated, the causal effects estimation is likely to be biased as the before-after differences being compared are not stable over time.

## Application using Card and Krueger (1994) data

We are going to examine Card and Krueger's paper on the effects of changes to minimum wage on employment in the fast food sector. The study uses geographic location of fast food workers as treatment and control groups to examine the effects of a state-level minimum wage increase, compared to a state where no increase took place. In the study, the **treatment group** is workers in **New Jersey** - where minimum wage increased from **\$4.25** to **\$5.05** in April 1992 - and the **control group** being workers in **Pennsylvania** - where minimum wage was not increased.

Conventional economic theory implies that, in labour markets with perfect competition, **increases in minimum wage lead to an increase in unemployment** - following the intuition that labour demand is inversely related to labour price. As seen in the figure below, this is some form of what in economics we call a *price floor*, which is the lowest legal price that can be paid in a market for a good / service, in this case, labor. This forms the **null hypothesis** for the experiment, and our basis for **causal inference**.

Attempting to establish a causal link between wage levels and employment has two snags:

1.  In theory, we observe employment and wage levels as a result of **equilibrium** between labour supply and demand. However, labour supply may be constrained by exogenous factors - such as introduction of minimum wage - resulting in the opposite of the null hypothesis stated above.

```{r, echo=FALSE, out.width = '75%'}
knitr::include_graphics(paste0(working_directory, "/labour.png"), error = FALSE)
```

We can get around this by observing **discrete** changes, such as the labour price shock caused by minimum wage change. Because this shock is **exogenous**, we can be sure that changes in employment levels are a consequence of it and not not the other way around.

2.  We require a **counter-factual** in order to quantify the effect of the exogenous shock to labour supply.

If we only looked at New Jersey before and after the increase in minimum wage, how could we be certain that the changes were effected by the shock? Also, what would have happened if there was no minimum wage increase? Since we cannot see what would happen in an alternate universe, what we could do is compare New Jersey to a place that is very similar. This is where we rely on Pennsylvania - our **control group** - to provide a counter-factual scenario where no shock takes place. Pennsylvania is selected because it is characteristically similar to New Jersey (at least in areas close to the border), and also will have similar fast-food restaurants to enable comparison. Restaurants in the bordering areas between the two states are considered relatively **homogenous**.

The use of (relatively) homogenous fast-food restaurants allows us to control for the state-specific differences between workers (state taxes, state GDP, state standards of living, etc.) by identifying them though their wages and working hours. This creates a credible counter-factual because we can "observe" the post-treatment in New Jersey had the minimum wage increase **not occurred** thanks to the similarity of fast-food workers in Pennsylvania.

### Setup

First, we need to load the Card and Kreuger data:

```{r}
data <- read.csv(paste0(working_directory, "/card_krueger_94.csv"))
```

This data was gathered by surveying employees at a representative sample of fast food restaurants with locations in both states before and after the minimum wage increase in New Jersey.

### Descriptive Statistics

Next, let's get familiar with the data by generating some descriptive statistics. We can have a look at the istribution of fast food restaurants (`chain`) in each state:

```{r, include=F}
rest_dist <- data %>%
  select(chain, state) %>%
  table() %>%
  prop.table(margin = 2)  %>%
  apply(MARGIN = 2,
        FUN = scales::percent_format(accuracy = 0.1)) %>%
  noquote
```

```{r}
print(rest_dist)
```

We can see that restaurant presence is broadly consistent between the two states.

They were looking at observations in two different periods (their "before" and "after" time periods):

- `observation` == "February 1992"
- `observation` == "November 1992"

, and focused on these variables:

-   `emptot` - Mean of total employees (full-time, part-time, and managers)
-   `pct_fte` - Mean percentage of employees that are full-time
-   `wage_st` - Mean starting wage for new employees
-   `hrs_open` - Mean operating hours (weekdays)

Let's filter data to the "before" or pre-treatment and look at average values ($\bar{Y}_{treatment,before}$) for variables: `emptot`, `pct_fte`, `wage_st`, `hrsopen`

```{r, include=F}
pre_treat <- data %>%
  filter(observation == "February 1992") %>%
  group_by(state) %>%
  summarise(emptot = mean(emptot, na.rm = TRUE),
            pct_fte  = mean(pct_fte, na.rm = TRUE),
            wage_st = mean(wage_st, na.rm = TRUE),
            hrsopen = mean(hrsopen, na.rm = TRUE)) %>%
  pivot_longer(cols=-state, names_to = "variable") %>%
  pivot_wider(names_from = state, values_from = value)
```

```{r}
pre_treat
```

Now, the same for "after" / post-treatment means ($\bar{Y}^{treatment,after}$):

```{r, include=F}
post_treat <- data %>%
  filter(observation == "November 1992") %>%
  group_by(state) %>%
  summarise(emptot = mean(emptot, na.rm = TRUE),
            pct_fte  = mean(pct_fte, na.rm = TRUE),
            wage_st = mean(wage_st, na.rm = TRUE),
            hrsopen = mean(hrsopen, na.rm = TRUE)) %>%
  pivot_longer(cols=-state, names_to = "variable") %>%
  pivot_wider(names_from = state, values_from = value)
```

```{r}
post_treat
```

We can see that wages on average increase in NJ, but remained the same in PA. If we assume they are very similar to each other, then we would say that wages and other outcomes would not have been affected in NJ as well (i.e., parallel trends)

### Visualisations

To understand this better, we can plot histograms of full-time employee wages in February and November 1992. We can see that the distribution of data changes for NJ and there is some 'bunching' happening a bit above minimum wage (around 75% of fast food restaurants in NJ). Additionally, this gives us an idea of the counterfactual for November 1992 had the treatment not occurred - the distribution of wages will have continued undisturbed.

```{r, warning=F}
# Instead of filtering data separately, we will create an object with our raw data but filter inside it using dplyr (the "%>%" notation)

hist_feb <- data %>%
  filter(observation == "February 1992") %>%      # Filter data pre-treatment
  ggplot(aes(x = wage_st, fill = state)) +
  geom_histogram(
    # "count" gets frequency, "tapply(..count.., ..group.., sum)" computes the total count of observations for each group (state).
    aes(y = (..count..) / tapply(..count.., ..group.., sum)[..group..] * 100), 
    position = "dodge",                           # bars for different states are placed side-by-side instead of stacked.
    bins = 23,                                    # number of bins
    alpha = 0.5                                   # transparency
  ) +
  geom_vline(                                     
    aes(xintercept = 4.25,                        # vertical line showing minimum wage
        color = "Minimum Wage"),                  # assigning label here, colour later
    linewidth = 1
  ) +
  labs(
    title = "February 1992",
    x = "Wage Range",
    y = "Percent of Stores",
    fill = "State",                                # This will fill histograms with colours based on number of states (in our case, two)
    color = ""                                     # No legend title for the minimum wage label we manually created
  ) +
  scale_fill_manual(values = c("blue", "red")) +               # legend with colours for two states
  scale_color_manual(values = c("Minimum Wage" = "yellow")) +   # manual legend for other labels (i.e., min wage line)
  theme_minimal()


hist_nov <- data %>%
  filter(observation == "November 1992") %>%
  ggplot(aes(x = wage_st, fill = state)) +
  geom_histogram(
    aes(y = (..count..) / tapply(..count.., ..group.., sum)[..group..] * 100), 
    position = "dodge",
    bins = 23,
    alpha = 0.5
  ) +
  geom_vline(
    aes(xintercept = 5.05, color = "Minimum Wage"),
    linewidth = 1
  ) +
  labs(
    title = "November 1992",
    x = "Wage Range",
    y = "Percent of Stores",
    fill = "State",
    color = ""
  ) +
  scale_fill_manual(values = c("blue", "red")) +
  scale_color_manual(values = c("Minimum Wage" = "yellow")) +
  theme_minimal()


print(hist_feb)
print(hist_nov)
```


### Average Treatment Effect Calculation

To calculate the treatment effect of increasing minimum wage in New Jersey, we must first calculate the differences:

```{r,message=F}
# Employee data grouped by "observation" (date / time) and "state" with average values
diffs <- data %>%
  group_by(observation, state) %>%
  summarise(emptot = mean(emptot, na.rm = T))

# New Jersey before treatment
njfeb <- diffs[1,3]
# Pennsylvania before treatment
pafeb <- diffs[2,3]
# New Jersey after treatment
njnov <- diffs[3,3]
# Pennsylvania after treatment
panov <- diffs[4,3]

print(diffs)
```

Next, we calculate the **average treatment effect** $\Delta\bar{Y}_{treatment} - \Delta\bar{Y}_{control}$ (the difference between the differences of pre-treatment and post-treatment within New Jersey and Pennsylvania):

```{r}
print((njnov - njfeb) - (panov - pafeb))
```

**2.75** is the increase in **mean of total employment** following the treatment, conflicting with our naive hypothesis already stated.

### Calculating Counter-factual Outcome

We also need to calculate the counter-factual outcome for New Jersey had the minimum wage increase not occurred (*parallel trends assumption*). So, we assume that the difference between PA's outcomes after the treatment (not affected) would be the same for New Jersey as well. Since employment dropped for 2.16% from 23.33 to 21.17 in PA, then we assume a similar drop would happen in NJ as well (from 20.44 - 2.16 = **18.27**). We write this in $\text{nj_counterfactual}$.

```{r}
nj_counterfactual <- tibble(
  observation = c("February 1992","November 1992"), 
  state = c("New Jersey (Counterfactual)","New Jersey (Counterfactual)"),
  emptot = as.numeric(c(njfeb, njfeb-(pafeb-panov)))
  ) 

# data points for treatment event (half way point between pre and post-treatmet for visuals)
intervention <- tibble(
    observation = c("Intervention", "Intervention", "Intervention"),
    state = c("New Jersey", "Pennsylvania", "New Jersey (Counterfactual)"),
    emptot = c(19.35, 22.3, 19.35)
  ) 

# combine data
did_plotdata <- bind_rows(diffs, 
                          nj_counterfactual, 
                          intervention)
```


### DID Plot

To best illustrate the treatment effect, we can create a plot of all three contingent parts of the analysis: pre-treatment, post-treatment, and counter-factual:

```{r, warning=F}
did_plotdata %>%
  mutate(label = if_else(observation == "November 1992", as.character(state), NA_character_)) %>%
  ggplot(aes(x=observation,y=emptot, group=state)) +
  geom_line(aes(color=state), size=1.2) +
  geom_vline(xintercept = "Intervention", linetype="dotted", 
             color = "black", size=1.1) + 
  scale_color_brewer(palette = "Accent") +
  scale_y_continuous(limits = c(17,24)) +
  ggrepel::geom_label_repel(aes(label = label),
                   nudge_x = 0.5, nudge_y = -0.5,
                   na.rm = TRUE) +
  guides(color=FALSE) +
  labs(x="", y="FTE Employment (mean)") +
  annotate(
    "text",
    x = "November 1992",
    y = 19.6,
    label = "{Difference-in-Differences}",
    angle = 90,
    size = 3
  ) +
  theme_minimal()
```

We can clearly see the effect of the minimum wage increase on mean of total employment, with the difference also appearing to agree with our average treatment effect of 2.75.

### Calculating DID Estimator

The final task is to calculate the DID estimator using linear regression. This provides the required empirical evidence to reject the naive hypothesis of increasing minimum wage causing an increase in unemployment.

Before running a regression, we need to create **dummy variables** for the time epochs before and after the treatment and the treated status of the observations:

Dummy variables in this instance are binary:

-   time = 1 if epoch is November 1992, 0 otherwise
-   treated = 1 if state is New Jersey, 0 otherwise

```{r}
data <- mutate(data,
               time = ifelse(observation == "November 1992", 1, 0), # create a dummy for "November 1992" (1 if yes; 0 if no / "February")
               treated = ifelse(state == "New Jersey", 1, 0)        # create a dummy for "New Jersey" (1 if yes; 0 if no / PA)
               )
```

Next, we estimate our model:

$$
\Large
\Delta emptot = \beta_0 + \beta_1 time + \beta_2 treatment + \beta_3 time * treatment + u
$$

To estimate the coefficient of the treatment on change in employment, we need to **interact** the time and treated dummy variables to stipulate that we want the effects in New Jersey in November 1992 (post-treatment). This interaction coefficient will be our DID estimator.

There are many ways of specifying interaction terms in R; here we have called **time:treated** after calling individual dummy variables **time** and **treated**, however you can also simply just call **time\*treated** for the same result.

```{r}
did_model = lm(emptot ~ time + treated + time:treated, data = data)
summary(did_model)
```

The DID estimator **time:treated** yields an estimate of **2.75**, matching our **average treatment effect** already recorded. We can reject our null hypothesis and conclude that the increase of minimum wage leads to an average increase in employment in New Jersey of **2.75** full time equivalent employees.








